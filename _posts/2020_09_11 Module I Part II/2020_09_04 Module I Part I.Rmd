---
title: "Cognitive Psychology Foundations - Module I Part II"
description: |
  I continue explore some foundational work investigating cognitive psychology, it's origins, and different ways in which the field has been studied.
author:
  - name: Lyndsay Hage
    url: https://lyndsaymh.github.io/Lyndsay-s-Cognitive-Psychology-Blog/
    affiliation: Hunter College - City University of New York
    affiliation_url: https://www.cuny.edu
date: 09-11-2020
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# Learn more about creating blogs with Distill at:
# https://rstudio.github.io/distill/blog.html

```

Hintzman’s (1986) paper focused on describing and running a computational model of memory inspired directly by Semon’s memory theory. Computational papers are definitely not my strength, but it was interesting to connect this paper with what I had learned from Schachter et al.’s (1978) paper as well as the lecture from my Cognitive Psychology course regarding Semon’s theory of memory (Crump, 2020). There is always something remarkable about following the lineage or convergence of scientific ideas across time and watching them expand, change, and develop as our methods of inquiry and our technological tools improve. If only Semon could see the simulation model, MINERVA 2, apply his concepts of memory. While he was unable to test his theory himself and relied heavily on introspection, I think he would feel quite validated to watch computer models test these ideas under different paradigms. 

This paper helped me to develop my understanding of this perspective of memory. In the Multiple Trace Memory Model, there is one memory system consisting of episodic traces that are stored in each person. With each new conscious experience, we develop more memory traces. Eventually, we develop a massive pool of traces called the secondary memory. When we see a cue to retrieve information or a “probe,” the primary memory is broadcast to all traces in the secondary memory simultaneously. Each trace is activated according to how many properties it shares with the initial probe. Not only can specific experiences be retrieved in this process, but also abstract knowledge which is derived from the pool of memory traces. To observe this relationship with abstract knowledge, Hintzman used the schema-abstraction task as it appears to capture the basic ways of learning to classify and allows for quite a bit of variable control. 

I really enjoyed thinking about memory in terms of resonance and wavelengths of energy. During my Cognitive Psychology lecture, Dr. Crump (2020) used the metaphor of hitting a middle C string on a piano (similar to the primary memory) and how the resulting vibrations physically broadcast and resonate with all the other strings in the piano (secondary memory). Strings on the piano (memory traces) with similar properties, such as C on different octaves from the probe C, will be the most activated in relation to strings that are less similar to the probe string (G, D, etc.). This string resonance is the echo that emanates back from the secondary memory. This analogy really helped me significantly to understand the theory behind the simulation. It also made this theory more tangible in my mind.

The discussion regarding the methods of running the MINERVA 2 model was a bit inaccessible for me, but I appreciated the justifications for how they developed the model and incorporated the different aspects of multiple trace memory theory. It is always interesting to see how characteristics within a phenomenon are derived in an equation. In this section of the paper, we could see how the characteristics of secondary memory’s “echo” such as intensity and content are derived mathematically so that the model can simulate these processes as the echo returns to the primary memory. 

The MINERVA 2 model was applied to the schema-abstraction paradigm to evaluate if subjects could obtain an “abstract idea” even though an abstraction like this was never previously stored. They found that it was able to retrieve an abstracted prototype of a category when cued with the category name and was able to retrieve a category name when cued with a category exemplar. This predicts basic findings from previous literature exploring this paradigm. Interestingly, the echo presented by MINERVA 2 resembled the prototype (that was not explicitly known) but was not an exact copy. The prototype was abstracted over the process of learning. It’s crazy computer can do this!

I cannot imagine the pain that Richard Semon felt when he decided to end his own life on December 27, 1918 (Schacter et al., 1978). If only we could reach back in time and give Semon a glimpse of the effect his work might have today and how his ideas have converged and inspired scientists to come. If we could, I think articles like Hintzman’s could have given him hope where he perhaps felt none. This is also a testament to other scientists who are similarly struggling for recognition and facing regular rejection. One may never personally know the impact a contribution might have to future generations. As long as scientists develop work that is ethical and well-designed, they can never know how important that work will be some day. 

-------

In reading Aujla et al’s (2019) article, I had fun learning about how search engine logic can be designed using cognitive psychology and the possibilities this has for the future! This work applied natural language processing theories as a basis for developing a computational method for interpreting the language of a user’s search submission. Using what is known about human language, this search engine was designed to provide search results that fit with the user’s intent rather than keyword matching alone.

Classic search engines use keyword matching when retrieving relevant documents but that doesn’t always provide the results one is actually looking for. I’ve used terrible search engines in the past and I have not been able to put into words what made them so bad. A search really isn’t about the exact key word that is being used, but the objective and meaning behind the specific combination of terms that used in the search. If I write keywords such as “dog Central America hairless sweater” in a search, it might be because I can’t remember the name of the dog breed that I am looking for, but my intent is to search the “Xoloitzcuintli” dog breed to find out if it gets cold in the winter. A search engine that can predict this would be valuable!

There is something about applied psychology that is so exciting! Sometimes, when going through numerous papers describing theories, modelling, and predictions, it becomes easy to lose track of how these theories manifest in real world. When reading about the predictive modeling of a troop of baboons’ spatial movements and group decision-making, the paper itself has is interesting. From it we can ask, what factors predict where a troop of baboons decide to move? Who do they decide to follow? Do they go off of group consensus? From my perspective, it becomes even more exciting once we apply this information to predict a troop that is, let’s say, repeatedly crop-raiding a farmer. This information is not only valid and interesting on its own but may actually help someone. If we predict when and why baboons come to crop-raid, we can develop ways to prevent or deter this behavior which protects the farmer from losing their livelihood and health and the baboons from getting into dangerous situations. 

It was really interesting to learn (loosely) what methods models such as the LSA, BEAGLE, and BEAGLE-RP use to track human language and how several of these models were used to develop the “Semantic Librarian” in this study. Again, this modelling emphasized word meaning rather than word matching. The progression of quantitative representations of word semantics over the years is astoundingly rapid. Language is so dynamic and it is truly a marvel these models can be developed to determine word meaning accurately. 

In this study, Aujla et al. (2019) used a large collection of documents from various experimental psychology journals to create the context that the model could read. The process of reading through this content helped to develop the semantic word vectors needed to create this search engine. This massive pool of information that the model could reference helped the it to determine the meanings of words within the context of experimental psychology journals. 

When we speak to one another, we do not evaluate each word independently, but in the framework of the sentence that word exists in. Using this logic, the model read each word in the context of every sentence, in of all of the documents in order to build a semantic memory vector for every word. This included what context the word existed in (summed up the environmental vectors of all the other words in the same sentence) and the order in which that word is placed in a sentence. This not only connected the words in the same sentence but also indirectly associated words of the same or similar meaning because these words (chair and recliner) had environmental vectors of common words (seat, sit, sat) that summed into their semantic representations. I’m connecting Hintzman’s (1986) explanation of memory trace where the activation of a trace through shared primitive properties with a probe can also spread to that trace’s other primitive properties that are not contained in the probe. A probe may activate an associated memory that contains information the probe does not contain – which is the basis of associative learning (Hintzman, 1986). 

Let’s see if I can predict something correctly: Imagine that I query “this dog barks and scratches” in a search engine designed around papers that only discuss the dog breed, Xoloitzcuintli and their area of origin, genetics, vocalizations (including barking), and behavior. The model created from these papers would likely also associate my query of “dog” with Mexico (where Xoloitzcuintli come from). The probe might cause the model to retrieve articles regarding “Mexico.” My probe had nothing to do with Mexico, but due to the limited corpus provided to the model, it might determine that similar words like “dog” and “Xoloitzcuintli” that are both associated with barking and scratching are also likely both associated with “Mexico.” With more information, the search engine would likely not make a mistake. 

It was really interesting reviewing the search interface and how it used a target article to find authors whose work was related to that article in question. This would be incredibly helpful for literature reviews and would cut down on the tedious, but necessary, searching that often occurs when preparing an experiment or writing a manuscript. The visualization of the articles and authors on a two-dimensional plot is also a really helpful way to visualize how plotted authors or articles are related to the target article. This way, one might prioritize which articles to review first by order of relevance. I wish more search engines displayed this.

This paper discussed how a user’s vocabulary and the vocabulary in the corpus provided to the search engine derives semantic meaning. This made me think about equitability in search engines. Within the English language alone, there are various dialects and variations that differ in their vocabulary, spelling, and grammar. Their ability to be mutually comprehensible between groups is varied as well. When search engines are designed, what vocabulary might their standard be set to? When validating models like those described in this paper, what standards are we using to determine their validity as a model for language? Most likely the standards are set based on white, college educated men who are most likely to be designing or testing these engines. It makes sense that queries on experimental psychology papers should be derived from experimental psychology papers, but what about similar “Semantic Librarians” that could be used by the general public? I think it is important to be mindful of how we develop these models and who we are developing them for. Developing ways to incorporate various dialects, such as African American Vernacular English (AAVE) or Aboriginal English from Australia might provide a bridge for members of communities who predominately use a variety of English that is different than the white standard that has historically existed.

----

First, I love when journal articles include a public significance statement. The more we can bridge scientific findings to the general community, the more we can encourage future scientists! One shouldn’t need to be completely familiar with all the terminology in order to access the general findings and potential implications of a journal article. 

I had no idea that there is a word-initiation/first-letter slowing effect (longer keystroke times for letters in the first position of a word compared with the other letters in a word) and a midword slowing effect (an inverted U shaped pattern with longer inter-keystroke intervals for letters in the middle of a word compared to letters at the beginning and ending of word). Reading about this made me very self-conscious of my typing as I wrote out my notes and has made me self-conscious of my typing now…  

I think it is really fascinating how scientists like Crump et al (2019) utilize mundane, everyday behaviors (such as typing) as windows into general processes such as how the human mind handles uncertainty and as how instance theory of automatization can inform how we learn a skill.  Studies that utilize “natural,” everyday behaviors in animals to investigate their behaviors are more likely to be successful at demonstrating an animal’s true abilities. Using an elephant’s naturally impressive ability to smell can help us see how it might discriminate quantities of food. 

Crump et al. used information theory to measure structure in natural texts and, through looking at letter uncertainty (H), they found that letters in first position and in the middle position had greater letter uncertainty than those in other positions. There is variation in the mean inter-keystroke intervals that instance theory of automation helps to address. 

How does a typist become faster at typing? Instance theory of automatization models predict that the more instances someone has at attempting a skill, through practice, the more memory traces are preserved in the brain. Memory traces are created and preserved in the brain every time a response is given to a stimulus. When we present that stimulus again, all stored instances are triggered to be retrieved. As the number of memory traces grow, with more experience with that stimulus, the retrieval times for the skill associated with that stimulus will decrease. Each memory trace varies in its retrieval time, so the more instances one has to build more memory traces the more likely there will be a memory trace that has a shorter retrieval time. Over time you become faster at typing! Every time a typist presses down on their familiar keyboard, memory traces are being activated and formed.

Using a model simulation of instance theory, they were able to predict mean reaction times for sets of items that vary in uncertainty and found that they were identical to the uncertainty (H) but were scaled based on constant factors. Instance theory can model how a general learning and memory process could produce typing performance in terms of (or as a function of letter uncertainty). With this in mind, instance theory could help optimize learning to type with all types of texts, including natural ones.

Instance theory emphasizes how important it is to automatization to practice a skill extensively and in numerous contexts in order to develop the skill. To improve keystroke speed and accuracy for example, one might practice extensively while taking care to practice in different setting and with different keyboards. Changing up the location of the typing as well as the keyboard with which one is typing with would develop many more memory traces associated with varied stimuli. This practice across multiple contexts can help a typist expand their reaction times and their ability to speedily get the job done.


Aujla, Crump, Cook, & Jamieson (2019). The Semanitc Librarian: A search engine built from vector-space models of semantics. Behavior Research Methods, 51(6). https://doi.org/10.3758/s13428-019-01268-4

Crump, Lai, & Brosowsky (2019). Instance Theory Predicts Information Theory: Episodic Uncertainty as a Determinant of Keystroke Dynamics. Canadian Journal of Experimental Psychology. http://dx.doi.org/10.1037/cep0000182

Crump, M. (2020, September 4). PSYC 73800 Cognitive Psychology: Overview. [Lecture Notes]. 

Hintzman, D.L. (1986). “Schema Abstraction in Multiple-Trace Memory Model. Psychological Review, 93(4), 411-428.

Schacter, D. J., Eich, J. E., & Tulving, E. (1978). Richard Semon’s Theory of Memory. Journal of Verbal Learning and Verbal Behavior, 17, 721-743. 

